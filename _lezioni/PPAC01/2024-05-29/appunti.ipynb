{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso di `lxml` con file HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html_string = '''\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Library</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"book\" id=\"1\">\n",
    "        <h2>Python Programming</h2>\n",
    "        <p>Author: John Doe</p>\n",
    "        <p>Year: 2020</p>\n",
    "    </div>\n",
    "    <div class=\"book\" id=\"2\">\n",
    "        <h2>Learning XML</h2>\n",
    "        <p>Author: Jane Smith</p>\n",
    "        <p>Year: 2018</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "root = etree.fromstring(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osserviamo che i libri sono rappresentati da dei `<div>` aventi la classe `book`.\n",
    "\n",
    "Per ottenere tutti i libri, possiamo dunque cercare all'interno della pagina, tutti i tag `<div>` con questa caratteristica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo usare il metodo `Element.findall()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element div at 0x10e072080>, <Element div at 0x10e071f00>]\n"
     ]
    }
   ],
   "source": [
    "books = root.findall('.//div[@class=\"book\"]')\n",
    "\n",
    "print(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oppure il metodo `Element.xpath()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element div at 0x10e072080>, <Element div at 0x10e071f00>]\n"
     ]
    }
   ],
   "source": [
    "books = root.xpath('//div[@class=\"book\"]')\n",
    "\n",
    "print(books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che abbiamo gli elementi che rappresentano i libri, possiamo cliclarli uno per uno ed estrarre le informazioni che ci interessano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book ID: 1\n",
      "Title: Python Programming\n",
      "Author: John Doe\n",
      "Year: 2020\n",
      "-------------------\n",
      "Book ID: 2\n",
      "Title: Learning XML\n",
      "Author: Jane Smith\n",
      "Year: 2018\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for book in books:\n",
    "\n",
    "    # L'ID è un attributo del <div> attuale (che è book), quindi lo otteniamo\n",
    "    # con il metodo .get()\n",
    "    book_id = book.get('id')\n",
    "\n",
    "    # Sappiamo che il titolo del libro è contenuto in un tag <h2>, che è unico\n",
    "    # all'interno del libro. Quindi il metodo .find() è sufficiente.\n",
    "    title = book.find('h2').text\n",
    "\n",
    "    # Invece l'autore e l'anno sono contenuti in un tag <p>. Tuttavia di questi\n",
    "    # tag ne abbiamo due, quindi per ottenerli entrambi, usiamo il metodo .findall()\n",
    "    paragraphs = book.findall('p')\n",
    "\n",
    "    # Ora dobbiamo cercare qual è il paragrafo contenente la parola \"Author\"\n",
    "    # quello contenente la parola \"Year\". Dato che queste parole sono all'inizio\n",
    "    # del testo, possiamo usare il metodo str.startswith()\n",
    "    for p in paragraphs:\n",
    "        if p.text.startswith('Author'):\n",
    "            # Infine facciamo lo split del testo sui due punti (:) e prediamo\n",
    "            # il secondo elemento della lista che ci viene restituita da .split()\n",
    "            author = p.text.split(': ')[1]\n",
    "        elif p.text.startswith('Year'):\n",
    "            year = p.text.split(': ')[1]\n",
    "\n",
    "    print(f\"Book ID: {book_id}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Year: {year}\")\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso, per l'autore e l'anno, il metodo `Element.xpath()` è invece molto più versatile di `Element.findall()`, perché consente di usare predicati e condizioni.\n",
    "\n",
    "Per esempio, se vogliamo trovare un tag `<p>` che contiene il testo \"Author\" o \"Year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book ID: 1\n",
      "Title: Python Programming\n",
      "Author: John Doe\n",
      "Year: 2020\n",
      "-------------------\n",
      "Book ID: 2\n",
      "Title: Learning XML\n",
      "Author: Jane Smith\n",
      "Year: 2018\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for book in books:\n",
    "    book_id = book.get('id')\n",
    "    title = book.find('h2').text\n",
    "    \n",
    "    # Il metodo .xpath() è molto più comodo \n",
    "    author_elem = book.xpath('.//p[contains(text(), \"Author\")]')[0]\n",
    "    year_elem = book.xpath('.//p[contains(text(), \"Year\")]')[0]\n",
    "    \n",
    "    author = author_elem.text.split(': ')[1]\n",
    "    year = year_elem.text.split(': ')[1]\n",
    "\n",
    "    print(f\"Book ID: {book_id}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Year: {year}\")\n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qual è la differenza tra i metodi `.findall()` e `.xpath()` degli `Element`?\n",
    "\n",
    "`findall()` fa parte dell'API originale di `ElementTree`. Supporta un semplice sottoinsieme del linguaggio XPath, senza predicati, condizioni e altre caratteristiche avanzate. È molto utile per trovare velocemente tag specifici in un albero.\n",
    "\n",
    "`xpath()`, invece, supporta tutta la potenza del linguaggio XPath, compresi i predicati, le funzioni XPath e le funzioni di estensione Python. La sintassi è definita dalle specifiche XPath. Se si ha bisogno dell'espressività e della selettività di XPath, il metodo `xpath()` è la scelta migliore.\n",
    "\n",
    "> PER APPROFONDIRE: [What are the findall() and xpath() methods on Element(Tree)?\n",
    "](https://lxml.de/FAQ.html#what-are-the-findall-and-xpath-methods-on-element-tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ulteriori informazioni sulla sintassi XPath\n",
    "\n",
    "- [XPath con `lxml`](https://lxml.de/xpathxslt.html)\n",
    "- [Cheatsheet 1](https://devhints.io/xpath)\n",
    "- [Cheatsheet 2](https://quickref.me/xpath.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempi di predicati e condizioni comuni XPath\n",
    "Ecco alcuni esempi di espressioni XPath con predicati e condizioni comuni che potrebbero esserti utili:\n",
    "\n",
    "- **Selezionare nodi in base al contenuto del testo**:\n",
    "  ```xpath\n",
    "  //p[contains(text(), \"Author\")]\n",
    "  ```\n",
    "\n",
    "- **Selezionare nodi in base a un attributo**:\n",
    "  ```xpath\n",
    "  //a[@href='http://example.com']\n",
    "  ```\n",
    "\n",
    "- **Selezionare nodi figli specifici**:\n",
    "  ```xpath\n",
    "  /root/child::node()\n",
    "  ```\n",
    "\n",
    "- **Selezionare nodi con un attributo specifico**:\n",
    "  ```xpath\n",
    "  //element[@attribute='value']\n",
    "  ```\n",
    "\n",
    "- **Selezionare nodi con più condizioni**:\n",
    "  ```xpath\n",
    "  //book[price>30 and @category='fiction']\n",
    "  ```\n",
    "\n",
    "- **Utilizzare operatori logici**:\n",
    "  ```xpath\n",
    "  //element[@attribute='value1' or @attribute='value2']\n",
    "  ```\n",
    "\n",
    "- **Selezionare nodi basati sulla posizione**:\n",
    "  ```xpath\n",
    "  //book[position()=1]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esempio pratico con `lxml` e XPath\n",
    "Per utilizzare questi predicati e condizioni con `lxml` in Python, ecco un esempio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "# Esempio XML\n",
    "xml_data = \"\"\"\n",
    "<library>\n",
    "    <book category=\"fiction\">\n",
    "        <title lang=\"en\">Harry Potter</title>\n",
    "        <author>J.K. Rowling</author>\n",
    "        <price>29.99</price>\n",
    "    </book>\n",
    "    <book category=\"non-fiction\">\n",
    "        <title lang=\"en\">A Brief History of Time</title>\n",
    "        <author>Stephen Hawking</author>\n",
    "        <price>15.99</price>\n",
    "    </book>\n",
    "</library>\n",
    "\"\"\"\n",
    "\n",
    "# Parsing dell'XML\n",
    "root = etree.fromstring(xml_data)\n",
    "\n",
    "# Esempio di XPath con predicati\n",
    "books = root.xpath('//book[price>20 and @category=\"fiction\"]')\n",
    "\n",
    "for book in books:\n",
    "    print(book.find('title').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"book\" id=\"1\">\n",
      "        <h2>Python Programming</h2>\n",
      "        <p>Author: John Doe</p>\n",
      "        <p>Year: 2020</p>\n",
      "    </div>\n",
      "    \n",
      "<div class=\"book\" id=\"3\">\n",
      "        <h2>XPath Superpowers</h2>\n",
      "        <p>Author: Dr. X</p>\n",
      "        <p>Year: 2020</p>\n",
      "    </div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "# Esempio HTML\n",
    "html_data = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Library</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"book\" id=\"1\">\n",
    "        <h2>Python Programming</h2>\n",
    "        <p>Author: John Doe</p>\n",
    "        <p>Year: 2020</p>\n",
    "    </div>\n",
    "    <div class=\"book\" id=\"2\">\n",
    "        <h2>Learning XML</h2>\n",
    "        <p>Author: Jane Smith</p>\n",
    "        <p>Year: 2018</p>\n",
    "    </div>\n",
    "    <div class=\"book\" id=\"3\">\n",
    "        <h2>XPath Superpowers</h2>\n",
    "        <p>Author: Dr. X</p>\n",
    "        <p>Year: 2020</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Parsing dell'HTML\n",
    "root = etree.fromstring(html_data)\n",
    "\n",
    "# Esempio di XPath con predicati\n",
    "books = root.xpath('//div[@class=\"book\" and p[contains(text(), \"Year: 2020\")]]')\n",
    "\n",
    "for book in books:\n",
    "    etree.dump(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduzione a BeautifulSoup\n",
    "\n",
    "Nel mondo del *web scraping* con Python, la libreria BeautifulSoup è quella storicamente più usata.\n",
    "\n",
    "A differenza di `lxml`, BeautifulSoup è dedicato esclusivamente ai file HTML ed utilizza principalmente i [selettori CSS](https://www.w3schools.com/cssref/css_selectors.php) per selezionare gli elementi desiderati all'interno di un documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installare `beautifulsoup4`:\n",
    "\n",
    "```cmd\n",
    "> pip install beautifulsoup4\n",
    "\n",
    "> py -m pip install beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Python Programming\n",
      "Author: John Doe\n",
      "Year: 2020\n",
      "\n",
      "\n",
      "XPath Superpowers\n",
      "Author: Dr. X\n",
      "Year: 2020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Dati in HTML\n",
    "html_data = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Library</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"book\" id=\"1\">\n",
    "        <h2>Python Programming</h2>\n",
    "        <p>Author: John Doe</p>\n",
    "        <p>Year: 2020</p>\n",
    "    </div>\n",
    "    <div class=\"book\" id=\"2\">\n",
    "        <h2>Learning XML</h2>\n",
    "        <p>Author: Jane Smith</p>\n",
    "        <p>Year: 2018</p>\n",
    "    </div>\n",
    "    <div class=\"book\" id=\"3\">\n",
    "        <h2>XPath Superpowers</h2>\n",
    "        <p>Author: Dr. X</p>\n",
    "        <p>Year: 2020</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Parsing dell'HTML\n",
    "soup = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "# Selezione degli elementi div con classe \"book\"\n",
    "# NOTA: div.book è un selettore CSS\n",
    "books = soup.select('div.book')\n",
    "\n",
    "for book in books:\n",
    "    paragraphs = book.find_all('p')\n",
    "    for p in paragraphs:\n",
    "        if \"Year: 2020\" in p.text:\n",
    "            print(book.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'[esercizio_26_xml_html.ipynb](../../../esercizi/esercizio_26_xml_html.ipynb) possiamo risolverlo anche usando la libreria BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book ID: 1\n",
      "Title: Python Programming\n",
      "Author: John Doe\n",
      "Year: 2020\n",
      "-------------------\n",
      "Book ID: 2\n",
      "Title: Learning XML\n",
      "Author: Jane Smith\n",
      "Year: 2018\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Esempio HTML\n",
    "html_data = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Library</title>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"book\" id=\"1\">\n",
    "        <h2>Python Programming</h2>\n",
    "        <p>Author: John Doe</p>\n",
    "        <p>Year: 2020</p>\n",
    "    </div>\n",
    "    <div class=\"book\" id=\"2\">\n",
    "        <h2>Learning XML</h2>\n",
    "        <p>Author: Jane Smith</p>\n",
    "        <p>Year: 2018</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Parsing dell'HTML\n",
    "soup = BeautifulSoup(html_data, 'html.parser')\n",
    "\n",
    "# Selezione degli elementi div con classe \"book\"\n",
    "books = soup.select('div.book')\n",
    "\n",
    "for book in books:\n",
    "    book_id = book.get('id')\n",
    "    title = book.find('h2').text\n",
    "    \n",
    "    # Trova l'elemento <p> contenente \"Author\"\n",
    "    author_elem = book.find('p', string=lambda x: \"Author\" in x)\n",
    "    # Trova l'elemento <p> contenente \"Year\"\n",
    "    year_elem = book.find('p', string=lambda x: \"Year\" in x)\n",
    "    \n",
    "    author = author_elem.text.split(': ')[1]\n",
    "    year = year_elem.text.split(': ')[1]\n",
    "\n",
    "    print(f\"Book ID: {book_id}\")\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Author: {author}\")\n",
    "    print(f\"Year: {year}\")\n",
    "    print(\"-------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiti per la prossima lezione\n",
    "\n",
    "Dare una lettura ai seguenti notebook:\n",
    "\n",
    "- [12_python_http.ipynb](../../../12_python_http.ipynb) fino al paragrafo \"Parametri delle *GET query string*\"\n",
    "\n",
    "- [13_python_spider.ipynb](../../../13_python_spider.ipynb) dal paragrafo \"Request + Beautiful Soup\" in avanti.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
